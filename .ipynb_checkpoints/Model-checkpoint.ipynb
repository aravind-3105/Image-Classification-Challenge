{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "82DFmOJZ5mF5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fea90ed2490>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import preprocessing\n",
    "from torchvision import transforms, utils\n",
    "from torchvision import models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import cv2\n",
    "from sklearn.metrics import f1_score,precision_score,log_loss\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BEEA7ixs5U91"
   },
   "outputs": [],
   "source": [
    "class FoodData(Dataset):\n",
    "    def __init__(self,dataFile,fileDir,transform=None,train=True):\n",
    "        super().__init__()\n",
    "        self.data_list = dataFile\n",
    "        self.data_dir = fileDir\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_list.shape[0]\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        if self.train:\n",
    "              img_name,label = self.data_list.iloc[item]\n",
    "        else:\n",
    "              img_name = self.data_list.iloc[item]['ImageId']\n",
    "        img_path = os.path.join(self.data_dir,img_name)\n",
    "        img = cv2.imread(img_path,1)\n",
    "        img = cv2.resize(img,(256,256))\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.train:\n",
    "              return {\n",
    "                  'gt' : img,\n",
    "                  'label' : torch.tensor(label)\n",
    "\n",
    "              }\n",
    "        else:\n",
    "              return {\n",
    "                  'gt':img\n",
    "              }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XOo5Q96onPVW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ImageId  ClassName\n",
      "0     f27632d7e5.jpg         55\n",
      "1     efa87919ed.jpg         41\n",
      "2     4f169e8c8d.jpg         12\n",
      "3     a6956654bf.jpg         44\n",
      "4     d99ce8c3bf.jpg         23\n",
      "...              ...        ...\n",
      "9318  ba8233c7d2.jpg          7\n",
      "9319  2090043907.jpg         58\n",
      "9320  8762d1cefd.jpg         14\n",
      "9321  28e7439245.jpg         12\n",
      "9322  ba263cfb41.jpg         21\n",
      "\n",
      "[9323 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "table = pd.read_csv('data/train/train.csv')\n",
    "Label_Encode = preprocessing.LabelEncoder()\n",
    "Labels = Label_Encode.fit_transform(table['ClassName'])\n",
    "trainData = table\n",
    "trainData['ClassName'] = Labels\n",
    "print(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.FoodData object at 0x7fea95666670>\n"
     ]
    }
   ],
   "source": [
    "trainPath = 'data/train/train_images'\n",
    "\n",
    "train_data = FoodData(dataFile = trainData,\n",
    "                           fileDir = trainPath,\n",
    "                           transform = transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5,0.5,0.5))\n",
    "                            ]))\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EYWQlhe5w_I"
   },
   "source": [
    "We load our train data and some necessary augementations like converting to PIL image, converting to tensors and normalizing them across channels. We can add more augementations such as `Random Flip`, `Random Rotation`, etc more on which can be found [here](https://pytorch.org/docs/stable/torchvision/transforms.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BBwgTv6v-JjC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.FoodData object at 0x7fea95666b80>\n"
     ]
    }
   ],
   "source": [
    "#Store test data\n",
    "testData = pd.read_csv('data/test/test.csv')\n",
    "testPath = 'data/test/test_images/'\n",
    "test_data = FoodData(dataFile = testData,\n",
    "                           fileDir = testPath,\n",
    "                           transform = transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5,0.5,0.5))\n",
    "                            ]),train=False)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KQx0SjTzC8rD"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "valid_size = 0.2\n",
    "num = train_data.__len__()\n",
    "# Dividing the indices for train and cross validation\n",
    "indices = list(range(num))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size*num))\n",
    "train_idx,valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "#Create Samplers\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "validation_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "\n",
    "trainDataLoader = DataLoader(train_data, \n",
    "                             batch_size=batch_size, \n",
    "                             num_workers=8,\n",
    "                             pin_memory = True,\n",
    "                             sampler=train_sampler)\n",
    "validDataLoader = DataLoader(train_data, \n",
    "                             batch_size=batch_size,\n",
    "                             num_workers=8,\n",
    "                             pin_memory=True,\n",
    "                             sampler=validation_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daFAO0Ez6qxv"
   },
   "source": [
    "Here we load test images. Note: This file will not have any labels with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ozAU2IdEDzCl"
   },
   "outputs": [],
   "source": [
    "#Test data\n",
    "testDataLoader = DataLoader(test_data, \n",
    "                             num_workers=4,\n",
    "                             pin_memory=True,\n",
    "                             batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "l_W_9ZtdD1Mb",
    "outputId": "0d16e386-309b-4083-e0ab-bab957b12b1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EYeJgQeSXhP7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/wandra/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f9272091744ca78f00faafa4b58d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "# class Net(nn.Module):\n",
    "#   # Define layers here\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "#         self.fc1 = nn.Linear(16 * 61 * 61, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 61)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#       # Forward pass\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 16 * 61 * 61)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5wgZsoAMEqpe"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#Loss Function\n",
    "error = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "ocymwmaNGFfg",
    "outputId": "85a7cab1-7033-4819-d9be-ebf47af49d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 LR: [1.0000000000000002e-06]\n",
      "Epoch: 0 \tTraining Loss: 0.445021 \tValidation Loss: 1.686230\n",
      "Validation Loss decreased inf -> 1.686230\n",
      "Epoch: 1 LR: [1.0000000000000002e-07]\n",
      "Epoch: 1 \tTraining Loss: 0.398195 \tValidation Loss: 1.691727\n",
      "Epoch: 2 LR: [1.0000000000000004e-08]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7641fd4c4c0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         Perform a single optimization step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "valid_loss_min = np.Inf\n",
    "model.cuda()\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    scheduler.step()\n",
    "    # Print Learning Rate\n",
    "    print('Epoch:', epoch,'LR:', scheduler.get_lr())\n",
    "    model.train()\n",
    "    for images in trainDataLoader:\n",
    "        data = images['gt'].squeeze(0).to(device)\n",
    "        # data = data.squeeze(0)\n",
    "        target = images['label'].to(device)\n",
    "#             clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "#         forward pass the model\n",
    "        output = model(data)\n",
    "#     backward pass the model\n",
    "        loss = error(output,target)\n",
    "        loss.backward()\n",
    "#         Perform a single optimization step\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    for images in validDataLoader:\n",
    "        data = images['gt'].squeeze(0).to(device)\n",
    "        target = images['label'].to(device)\n",
    "#         forward pass now\n",
    "        output = model(data)\n",
    "#         calculate the branch loss\n",
    "        loss = error(output, target)\n",
    "#     update average validation loss\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    train_loss /= len(trainDataLoader.sampler)\n",
    "    valid_loss /= len(validDataLoader.sampler)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print(\"Validation Loss decreased {:0.6f} -> {:0.6f}\".format(valid_loss_min,valid_loss))\n",
    "        valid_loss_min = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model_so_far.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "aFau5IeyG3c3",
    "outputId": "0dcd5d39-2526-4ef9-e220-cb280c5822e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 45.815451 %\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_so_far.pth'))\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "pred_list = []\n",
    "correct_list = []\n",
    "model.cuda()\n",
    "with torch.no_grad():\n",
    "    for images in validDataLoader:\n",
    "        data = images['gt'].squeeze(0).to(device)\n",
    "        target = images['label'].to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        pr = predicted.detach().cpu().numpy()\n",
    "        for i in pr:\n",
    "                pred_list.append(i)\n",
    "        tg = target.detach().cpu().numpy()\n",
    "        for i in tg:\n",
    "              correct_list.append(i)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qE19LWBnhowq"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model_so_far.pth'))\n",
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for images in testDataLoader:\n",
    "        data = images['gt'].squeeze(0).to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        pr = predicted.detach().cpu().numpy()\n",
    "        for i in pr:\n",
    "              preds.append(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nCB-d-yDUEc"
   },
   "source": [
    "## Save it in correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LGiuketcDOYg"
   },
   "outputs": [],
   "source": [
    "# Create Submission file        \n",
    "df = pd.DataFrame(Label_Encode.inverse_transform(preds),columns=['ClassName'])\n",
    "df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n",
      "__CUDNN VERSION: 8005\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n",
      "Available devices  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "FOODC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
